import os
import pickle
import faiss
from datetime import datetime
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from PIL import Image
import io

# --- åƒæ•¸è¨­å®šå€ ---
USE_FAISS = True             # âœ… æ˜¯å¦ä½¿ç”¨å‘é‡çŸ¥è­˜åº«(RAG)
USE_IMAGE = False             # âœ… æ˜¯å¦å•Ÿç”¨åœ–ç‰‡ç†è§£åŠŸèƒ½
API_KEY_FILE = "api-key.txt"
INDEX_FILE = "faiss_index.index"
SOURCE_FILE = "doc_sources.pkl"
EMBEDDING_MODEL = "paraphrase-multilingual-mpnet-base-v2"
TOP_K = 10
L2_THRESHOLD = 1

# --- åˆå§‹åŒ– API Key èˆ‡ Gemini æ¨¡å‹ ---
if not os.path.exists(API_KEY_FILE):
    raise FileNotFoundError(f"æ‰¾ä¸åˆ° API é‡‘é‘°æª”æ¡ˆï¼š{API_KEY_FILE}")

with open(API_KEY_FILE, "r", encoding="utf-8") as f:
    api_key = f.read().strip()

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.0-flash")
chat = model.start_chat()

# --- å•Ÿç”¨ Multimodal æ¨¡å‹ï¼ˆåœ–ç‰‡è¾¨è­˜ï¼‰ ---
if USE_IMAGE:
    multimodal_model = genai.GenerativeModel("gemini-1.5-flash")
    image_chat = multimodal_model.start_chat()

def read_image_bytes(image_path):
    with open(image_path, "rb") as f:
        return f.read()

def chat_with_image(image_path, user_prompt):
    image_bytes = read_image_bytes(image_path)
    image_pil = Image.open(io.BytesIO(image_bytes))
    response = image_chat.send_message([user_prompt, image_pil])
    return response.text

# --- FAISS åˆå§‹åŒ– ---
if USE_FAISS:
    index = faiss.read_index(INDEX_FILE)
    with open(SOURCE_FILE, "rb") as f:
        data = pickle.load(f)
    docs = data["docs"]
    sources = data["sources"]
    embedder = SentenceTransformer(EMBEDDING_MODEL)

# --- å°è©±æ­·å²å„²å­˜æª”æ¡ˆ ---
start_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
history_filename = f"chat_history_{start_time}.txt"

# --- Gemini ä¸»å°è©±é‚è¼¯ ---
def chat_with_gemini(user_input):
    if USE_FAISS:
        query_vector = embedder.encode([user_input], convert_to_numpy=True)
        query_vector = query_vector.reshape(1, -1)

        assert query_vector.shape[1] == index.d, f"âŒ ç¶­åº¦éŒ¯èª¤ï¼šæŸ¥è©¢å‘é‡ç‚º {query_vector.shape[1]}ï¼Œç´¢å¼•ç‚º {index.d}"

        D, I = index.search(query_vector, TOP_K)
        valid_results = [(docs[i], sources[i], d) for i, d in zip(I[0], D[0]) if d < L2_THRESHOLD]

        if valid_results:
            match_count = len(valid_results)
            print(f"ğŸ” æ‰¾åˆ° {match_count} ç­†ç›¸ä¼¼è³‡æ–™")
            context = "\n".join(f"[{src}] {chunk}" for chunk, src, _ in valid_results)
            prompt = f"ä½ æ˜¯ä¸€å€‹è°æ˜çš„ AI åŠ©ç†ï¼Œè«‹åƒè€ƒä»¥ä¸‹è³‡æ–™å’Œä½ çš„çŸ¥è­˜å›ç­”å•é¡Œï¼š\n\n{context}\n\nå•é¡Œï¼š{user_input}"
        else:
            print("âš ï¸ æ‰¾ä¸åˆ°ç›¸ä¼¼è³‡æ–™ï¼Œæ”¹ä»¥ LLM æ¨¡å‹çŸ¥è­˜å›ç­”")
            prompt = f"æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ã€‚è«‹ä¾ä½ è‡ªå·±çš„çŸ¥è­˜å›ç­”ä»¥ä¸‹å•é¡Œï¼š\nå•é¡Œï¼š{user_input}"
    else:
        prompt = user_input

    response = chat.send_message(prompt)
    return response.text

# --- ä¸»äº’å‹•ä»‹é¢ ---
if __name__ == "__main__":
    print("ğŸ¤– Gemini Chat CLI å·²å•Ÿå‹•ï¼ˆè¼¸å…¥ 'exit' æˆ– 'quit' é›¢é–‹ï¼‰")
    print("ğŸ“š å·²å•Ÿç”¨çŸ¥è­˜åº«æŸ¥è©¢æ¨¡å¼\n" if USE_FAISS else "ğŸ’¬ ä½¿ç”¨ç´” LLM æ¨¡å¼ï¼ˆæœªå•Ÿç”¨çŸ¥è­˜åº«ï¼‰")
    if USE_IMAGE:
        print("ğŸ–¼ï¸ åœ–ç‰‡ç†è§£åŠŸèƒ½å·²å•Ÿç”¨ï¼ˆä½¿ç”¨æ ¼å¼ï¼šimg: ./example.jpg æ‚¨çš„å•é¡Œï¼‰\n")

    while True:
        user_input = input("æ‚¨ï¼š").strip()
        if user_input.lower() in {"exit", "quit"}:
            print(f"ğŸ“„ å°è©±å·²å„²å­˜ç‚ºï¼š{history_filename}")
            print("ğŸ‘‹ å†è¦‹ï¼")
            break

        if USE_IMAGE and user_input.startswith("img:"):
            try:
                parts = user_input[4:].strip().split(" ", 1)
                image_path = parts[0]
                prompt = parts[1] if len(parts) > 1 else "è«‹èªªæ˜é€™å¼µåœ–çš„å…§å®¹"
                reply = chat_with_image(image_path, prompt)
            except Exception as e:
                reply = f"âŒ åœ–ç‰‡è™•ç†éŒ¯èª¤ï¼š{str(e)}"
        else:
            reply = chat_with_gemini(user_input)

        print("Geminiï¼š", reply)

        try:
            with open(history_filename, "a", encoding="utf-8") as f:
                f.write(f"ä½ ï¼š{user_input}\n\nGeminiï¼š{reply}\n\n")
        except Exception as e:
            print(f"âŒ ç„¡æ³•å„²å­˜å°è©±ç´€éŒ„ï¼š{str(e)}")

