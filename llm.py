import os
import pickle
import faiss
from datetime import datetime
from sentence_transformers import SentenceTransformer
import google.generativeai as genai

# --- è¨­å®šå€ ---
USE_FAISS = True
API_KEY_FILE = "api-key.txt"
INDEX_FILE = "faiss_index.index"
SOURCE_FILE = "doc_sources.pkl"
EMBEDDING_MODEL = "paraphrase-multilingual-mpnet-base-v2"
TOP_K = 10
L2_THRESHOLD = 0.75

# --- åˆå§‹åŒ– Gemini ---
if not os.path.exists(API_KEY_FILE):
    raise FileNotFoundError(f"æ‰¾ä¸åˆ° API é‡‘é‘°æª”æ¡ˆï¼š{API_KEY_FILE}")

with open(API_KEY_FILE, "r", encoding="utf-8") as f:
    api_key = f.read().strip()

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.0-flash")
chat = model.start_chat()

# --- åˆå§‹åŒ– FAISS èˆ‡åµŒå…¥æ¨¡å‹ ---
if USE_FAISS:
    index = faiss.read_index(INDEX_FILE)
    with open(SOURCE_FILE, "rb") as f:
        data = pickle.load(f)
    docs = data["docs"]
    sources = data["sources"]
    embedder = SentenceTransformer(EMBEDDING_MODEL)

# --- å„²å­˜æ­·å²æª”æ¡ˆ ---
start_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
history_filename = f"chat_history_{start_time}.txt"

# --- å°è©±è™•ç†å‡½å¼ ---
def chat_with_gemini(user_input):
    if USE_FAISS:
        query_vector = embedder.encode([user_input], convert_to_numpy=True)
        query_vector = query_vector.reshape(1, -1)

        assert query_vector.shape[1] == index.d, f"âŒ ç¶­åº¦éŒ¯èª¤ï¼šæŸ¥è©¢å‘é‡ç‚º {query_vector.shape[1]}ï¼Œç´¢å¼•ç‚º {index.d}"

        D, I = index.search(query_vector, TOP_K)
        valid_results = [(docs[i], sources[i], d) for i, d in zip(I[0], D[0]) if d < L2_THRESHOLD]

        if valid_results:
            context = "\n".join(f"[{src}] {chunk}" for chunk, src, _ in valid_results)
            prompt = f"ä½ æ˜¯ä¸€å€‹è°æ˜çš„ AI åŠ©ç†ï¼Œè«‹åƒè€ƒä»¥ä¸‹è³‡æ–™å’Œä½ çš„çŸ¥è­˜å›ç­”å•é¡Œï¼š\n\n{context}\n\nå•é¡Œï¼š{user_input}"
        else:
            prompt = f"æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ã€‚è«‹ä¾ä½ è‡ªå·±çš„çŸ¥è­˜å›ç­”ä»¥ä¸‹å•é¡Œï¼š\nå•é¡Œï¼š{user_input}"
    else:
        prompt = user_input

    response = chat.send_message(prompt)
    ai_reply = response.text

    with open(history_filename, "a", encoding="utf-8") as f:
        f.write(f"ä½ ï¼š{user_input}\n\nGeminiï¼š{ai_reply}\n\n")

    return ai_reply

# --- ä¸»äº’å‹•ä»‹é¢ ---
if __name__ == "__main__":
    print("ğŸ¤– Gemini Chat CLI å·²å•Ÿå‹•ï¼ˆè¼¸å…¥ 'exit' æˆ– 'quit' é›¢é–‹ï¼‰")
    print("ğŸ“š å·²å•Ÿç”¨çŸ¥è­˜åº«æŸ¥è©¢æ¨¡å¼\n" if USE_FAISS else "ğŸ’¬ ä½¿ç”¨ç´” LLM æ¨¡å¼ï¼ˆæœªå•Ÿç”¨çŸ¥è­˜åº«ï¼‰\n")

    while True:
        user_input = input("ä½ ï¼š")
        if user_input.strip().lower() in {"exit", "quit"}:
            print(f"ğŸ“„ å°è©±å·²å„²å­˜ç‚ºï¼š{history_filename}")
            print("ğŸ‘‹ å†è¦‹ï¼")
            break
        reply = chat_with_gemini(user_input)
        print("Geminiï¼š", reply)
